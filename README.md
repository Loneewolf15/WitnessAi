# ğŸ‘ WitnessAI
### Real-Time Crime Scene Intelligence Agent
**Vision Possible: Agent Protocol Hackathon 2026 â€” Built to Win**

---

## What It Does

WitnessAI transforms any live video feed into an **intelligent, always-on legal witness**. It watches, listens, narrates aloud, and documents â€” automatically.

- ğŸ¥ **YOLOv8 + IoU Tracker** detects and tracks every person in the scene
- ğŸ§  **Gemini Realtime at 5fps** watches the video and responds to voice questions
- ğŸ™ **Deepgram STT** â€” operator speaks naturally: *"What do you see? Package the evidence."*
- ğŸ”Š **ElevenLabs TTS** â€” WitnessAI narrates incidents aloud the moment they happen
- âš™ï¸ **5 SDK Tools** â€” Gemini calls backend functions mid-conversation to query status, retrieve narratives, and trigger evidence packaging
- ğŸ“Š **Live Operator Dashboard** at `http://localhost:8000` â€” anomaly log, metrics, narrative feed, evidence download
- ğŸ“¦ **Auto Evidence Packages** â€” JSON report + MP4 clip saved on every confirmed incident

---

## Architecture

```
Stream WebRTC Edge (sub-30ms)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Vision Agents SDK            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  WitnessProcessor            â”‚   â”‚  â† VideoProcessorPublisher
â”‚  â”‚  (witness_processor.py)      â”‚   â”‚
â”‚  â”‚  â€¢ av.VideoFrame decode      â”‚   â”‚
â”‚  â”‚  â€¢ WitnessAgent pipeline     â”‚   â”‚
â”‚  â”‚  â€¢ Frame annotation + HUD    â”‚   â”‚
â”‚  â”‚  â€¢ Latency measurement       â”‚   â”‚
â”‚  â”‚  â€¢ WebSocket broadcast       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚
â”‚  gemini.Realtime(fps=5)  â†â†’ video   â”‚  â† Watches & understands at 5fps
â”‚  deepgram.STT()          â†â†’ audio   â”‚  â† Operator speaks to the agent
â”‚  elevenlabs.TTS()        â†â†’ audio   â”‚  â† Agent speaks alerts aloud
â”‚                                      â”‚
â”‚  Tools (5 SDK function_tools):       â”‚  â† Gemini calls these mid-conversation
â”‚    get_agent_status()               â”‚
â”‚    get_scene_description()          â”‚
â”‚    get_incident_narrative()         â”‚
â”‚    package_incident_evidence()      â”‚
â”‚    list_evidence_packages()         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚
         â–¼                   â–¼
  Annotated feed      FastAPI + WS Server
  (back to call)      http://localhost:8000
                      /api/v1/incidents
                      /api/v1/packages/{id}/report
                      /ws/live  â† React dashboard
```

---

## Setup (3 steps)

### Step 1 â€” Get API keys (all free tiers available)

| Key | Where | Used for |
|---|---|---|
| `STREAM_API_KEY` + `STREAM_API_SECRET` | [getstream.io/try-for-free](https://getstream.io/try-for-free) | WebRTC video edge |
| `GOOGLE_API_KEY` | [aistudio.google.com](https://aistudio.google.com) | Gemini Realtime 5fps |
| `DEEPGRAM_API_KEY` | [deepgram.com](https://deepgram.com) | Operator voice input |
| `ELEVENLABS_API_KEY` | [elevenlabs.io](https://elevenlabs.io) | Agent voice output |

### Step 2 â€” Install

```bash
bash setup.sh
# OR manually:
pip install "vision-agents[getstream,gemini,ultralytics,deepgram,elevenlabs]" \
            fastapi uvicorn opencv-python-headless python-dotenv scipy
```

### Step 3 â€” Configure & run

```bash
# Edit .env â€” add your 4 API keys
python main.py join

# Dashboard opens at http://localhost:8000
# API docs at       http://localhost:8000/docs
```

---

## What the Judge Sees

| Criterion | What we do | Score |
|---|---|---|
| **Potential Impact** | Replaces missing documentation layer in ALL existing security systems | âœ… |
| **Creativity** | "AI Legal Witness" â€” documents, not just detects. Pre-crime buffer. | âœ… |
| **Technical Excellence** | YOLOv8 + IoU tracker + anomaly rules engine + 98 tests | âœ… |
| **Real-Time Performance** | 5fps Gemini, <50ms pipeline latency shown live on HUD | âœ… |
| **User Experience** | Live operator dashboard + voice in/out + annotated video feed | âœ… |
| **Best Use of Vision Agents** | `Realtime`, `STT`, `TTS`, `VideoProcessorPublisher`, 5 `function_tool`s, `Edge` | âœ… |

---

## Anomaly Detection

| Anomaly | Detection Method | Default Threshold |
|---|---|---|
| Loitering | Stationary frames counter | 30 seconds |
| Running | Track velocity (px/sec) | 150 px/s |
| Crowd Surge | Person count in frame | 8 persons |
| Fall Detected | Bounding box aspect ratio (prone) | width/height > 2.5 |

All configurable in `.env`.

---

## Voice Interaction Examples

Operator says â†’ WitnessAI responds:

> *"What do you see?"* â†’ calls `get_scene_description()`, narrates scene aloud
> *"What happened?"* â†’ calls `get_incident_narrative('latest')`, reads full report
> *"Package the evidence"* â†’ calls `package_incident_evidence('latest')`, confirms via voice
> *"How many packages do we have?"* â†’ calls `list_evidence_packages()`, gives count

---

## Evidence Package Contents

```
evidence_packages/
â””â”€â”€ {incident_id}/
    â”œâ”€â”€ {package_id}.mp4           â† 30s pre + post crime video
    â””â”€â”€ {package_id}_report.json  â† Full report:
                                      - Timestamped anomaly log
                                      - AI-generated narrative (LLM)
                                      - Track IDs + velocities
                                      - Confidence levels
                                      - Camera metadata
```

Download via: `GET /api/v1/packages/{incident_id}/report`

---

## Tests

```bash
python -m unittest tests.test_all tests.test_integration -v
# 98 tests, 0 failures, 6 skipped (SDK integration â€” need real keys)
```

---

*WitnessAI â€” The AI that doesn't just watch. It testifies.*
